# -*- coding: utf-8 -*-
"""proyek rekomendasi sumbiss mlt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k4nPs39QtJ-vu_d73bE128-Fnm5GqK0t

# Laporan Proyek ML Sistem Rekomendasi - Rizky Adhi Nugroho
* Email : nugrohorizkyadhi@gmail.com
#### Sistem rekomendasi untuk Buku

metode :
1.   Content based Filtering
2.   Collaborative filtering

## Data Loading

### import library dan dataset
"""

# Import library
import pandas as pd
import numpy as np 
from zipfile import ZipFile
from pathlib import Path
import matplotlib.pyplot as plt

#import data dari drive
from google.colab import drive
drive.mount('/content/drive')

"""### Ekstrak zip file"""

! unzip /content/drive/MyDrive/Booksrate.zip

"""### buat path untuk dataset"""

import warnings 
warnings.filterwarnings('ignore')

rate = pd.read_csv('/content/BX-Book-Ratings.csv', 
                 sep=';', encoding = "ISO-8859-1") 
rate.tail()

df1 = pd.read_csv('/content/BX_Books.csv', 
                 sep=';', encoding = "ISO-8859-1") 
df1.tail()

"""### deskripsi dataset (Eda Univariate)

#### dataset rate
"""

print(rate.describe())
print(rate.info())
print(rate.shape)

"""#### dataset df1 (book)"""

print(df1.describe())
print(df1.info())
print(df1.shape)

"""## Data Pre-Processing & Preparation

### cek unique value
"""

#jumlah data unik berdasarkan kolom ISBN dari rating
print('Banyak data unik isbn rate: ', len(rate.ISBN.unique()))

#jumlah data unik berdasarkan kolom ISBN dari df1
print('Banyak data unik isbn df1: ', len(df1.ISBN.unique()))

"""### gabungkan dua file menjadi 1 dataset"""

rating_info = pd.concat([rate])

# Menggabungkan dataframe rating dengan book berdasarkan nilai ISBN
buku = pd.merge(rating_info, df1, on='ISBN', how='left')
buku

"""### deskripsi dataset setelah digabungkan"""

buku.info()

"""### drop kolom yang tidak terpakai"""

# menghapus kolom yang tidak terpakai pada data clean
kol = [5,6,7,8,9]
buku.drop(buku.columns[kol],axis=1,inplace=True)

"""### cek missing value dan menanganinya"""

#cek missing value
print(buku.shape)
buku.isnull().sum()

# Membersihkan missing value dengan fungsi dropna()
clean = buku.dropna()

#cek missing value setelah di clean
print(clean.shape)
clean.isnull().sum()

# Mengecek berapa jumlah ISBN unik pada dataset clean
print('nomor ISBN unik :', len(clean.ISBN.unique()))
clean

#mengurutkan data clean berdasarkan ISBN
preparation = clean.sort_values('ISBN', ascending=True)
preparation

"""### bersihkan data terduplikasi"""

# Membuang data duplikat pada variabel preparation
df = preparation.drop_duplicates('ISBN')
df

"""### Buat plot untuk data rating"""

import matplotlib.pyplot as plt

count = df['Book-Rating'].value_counts()
percent = 100*df['Book-Rating'].value_counts(normalize=True)
dt = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(dt)
count.plot(kind='bar', title='Book-Rating');

"""### konversi data ke bentuk list"""

# Mengonversi data series ‘ISBN’ menjadi dalam bentuk list
id_buku = df['ISBN'].tolist()
 
# Mengonversi data series ‘Book-Title’ menjadi dalam bentuk list
nama_buku = df['Book-Title'].tolist()
 
# Mengonversi data series ‘Book-Author’ menjadi dalam bentuk list
pengarang = df['Book-Author'].tolist()
 
print(len(id_buku))
print(len(nama_buku))
print(len(pengarang))

"""###membuat dictionary"""

# Membuat dictionary untuk data ‘book_id’, ‘book_name’, dan ‘pengarang’
data = pd.DataFrame({
    'id': id_buku,
    'book_name': nama_buku,
    'pengarang': pengarang
})
data

"""##model content based filtering

### TF-IDF Vectorizer
"""

#membuat sistem rekomendasi buku berdasarkan pengarang buku
from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data pengarang
tf.fit(data['pengarang']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['pengarang']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""### Membuat dataframe untuk melihat tf-idf matrix"""

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan pengarang
# Baris diisi dengan nama buku
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.book_name
).sample(22, axis=1).sample(10, axis=0)

"""### cosine similarity"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama book
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['book_name'], columns=data['book_name'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap book
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Menampilkan Buku rekomendasi"""

def book_recommendations(nama_buku, similarity_data=cosine_sim_df, items=data[['book_name', 'pengarang']], k=5):

    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_buku].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_book agar nama book yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_buku, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

data[data.book_name.eq('Fantastic Beasts and Where to Find Them')]

# Mendapatkan rekomendasi book yang mirip dengan harry potter
book_recommendations('Fantastic Beasts and Where to Find Them')

data[data.book_name.eq('Dreamcatcher')]

# Mendapatkan rekomendasi book yang mirip dengan dreamcatcher
book_recommendations('Dreamcatcher')

data[data.book_name.eq('Ashes to Ashes')]

# Mendapatkan rekomendasi book yang mirip dengan ashes to asesh
book_recommendations('Ashes to Ashes')

data[data.book_name.eq('Heaven and Earth (Three Sisters Island Trilogy)')]

# Mendapatkan rekomendasi book yang mirip dengan heaven and earth
book_recommendations('Heaven and Earth (Three Sisters Island Trilogy)')

"""## model collaborative

### menyiapkan dataset
"""

# Membaca dataset
 
df = rate
df

"""### data preparation (encode fitur user-id dan ISBN)"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['User-ID'].unique().tolist()
print('list userID: ', user_ids)
 
# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)
 
# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

# Mengubah ISBN menjadi list tanpa nilai yang sama
ISBN_ids = df['ISBN'].unique().tolist()
 
# Melakukan proses encoding ISBN
book_to_book_encoded = {x: i for i, x in enumerate(ISBN_ids)}
 
# Melakukan proses encoding angka ke 
book_encoded_to_book = {i: x for i, x in enumerate(ISBN_ids)}
 
#Selanjutnya, petakan userID dan ISBN ke dataframe yang berkaitan.
 
# Mapping userID ke dataframe user
df['user'] = df['User-ID'].map(user_to_user_encoded)
 
# Mapping ISBN ke dataframe book
df['book'] = df['ISBN'].map(book_to_book_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
 
# Mendapatkan jumlah book
num_book = len(book_encoded_to_book)
print(num_book)
 
# Mengubah rating menjadi nilai float
df['Book-Rating'] = df['Book-Rating'].values.astype(np.float32)
 
# Nilai minimum rating
min_rating = min(df['Book-Rating'])
 
# Nilai maksimal rating
max_rating = max(df['Book-Rating'])
 
print('Number of User: {}, Number of book: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

"""### Membagi Data untuk Training dan Validasi"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

# Membuat variabel x untuk mencocokkan data user dan book menjadi satu value
x = df[['user', 'book']].values
 
# Membuat variabel y untuk membuat rating dari hasil 
y = df['Book-Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_book, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_book = num_book
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.book_embedding = layers.Embedding( # layer embeddings book
        num_book,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.book_bias = layers.Embedding(num_book, 1) # layer embedding book bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    book_vector = self.book_embedding(inputs[:, 1]) # memanggil layer embedding 3
    book_bias = self.book_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_book = tf.tensordot(user_vector, book_vector, 2) 
 
    x = dot_user_book + user_bias + book_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""### modeling dan training"""

model = RecommenderNet(num_users, num_book, 50) # inisialisasi model
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training
 
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""### visualisasi metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## mendapatkan rekomendasi"""

book_df = data
df = pd.read_csv('BX-Book-Ratings.csv', sep=';')
print(df)
# Mengambil sample user
user_id = df['User-ID'].sample(42).iloc[0]
book_read_by_user = df[df['User-ID'] == user_id]
 
# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html 
book_not_read = book_df[~book_df['id'].isin(book_read_by_user.ISBN.values)]['id'] 
book_not_read = list(
    set(book_not_read)
    .intersection(set(book_to_book_encoded.keys()))
)
 
book_not_read = [[book_to_book_encoded.get(x)] for x in book_not_read]
user_encoder = user_to_user_encoded.get(user_id)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_not_read), book_not_read)
)

ratings = model.predict(user_book_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_book_ids = [
    book_encoded_to_book.get(book_not_read[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 10)
print('book with high ratings from user')
print('----' * 8)
 
top_book_user = (
    book_read_by_user.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
 
book_df_rows = book_df[book_df['id'].isin(top_book_user)]
for row in book_df_rows.itertuples():
    print(row.book_name, '| from |', row.pengarang)
 
print('----' * 8)
print('Top 10 book recommendation')
print('----' * 8)
 
recommended_book = book_df[book_df['id'].isin(recommended_book_ids)]
for row in recommended_book.itertuples():
    print(row.book_name, '| from |', row.pengarang)